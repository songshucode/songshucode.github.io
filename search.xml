<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tensorflow-model-save]]></title>
    <url>%2F2019%2F07%2F02%2Ftensorflow-model-save%2F</url>
    <content type="text"><![CDATA[save model using tensorflow; read the model file saved to view model weights and structure. Also, you can wiew the model structure you build. save modelsave a modelIt’s a simple method by the tensorflow. model_name is the name you want use it to name your model. when you do the following command, you will get four files, *.index, *.data-xxx, *.meta and the checkpoing file.123456... # define the model graphsaver = tf.train.Saver()sess = tf.Session()... # run the modelsaver.save(sess, model_name) # save modelsess.close() save a model without saving the model graphsometimes, you only want to save the model weights but not the model graph, you can use the following command.1saver.save(sess, model_name, write_meta_graph=False) save a model by the training stepusing the training step, you can record model weights on the different training step. and you also define the maximum number you want to seve.1saver.save(sess, model_name, max_to_keep=4, global_step=step) save a model by the training timesave the model at regular time intervals.1saver.save(sess, model_name, max_to_keep=4, keep_checkpoint_every_n_hours=2) only save a part of model weightssometimes, you don’t need save all the model variables.123saver = tf.train.Saver([w1, w2])...saver.save(sess, model_name) load modelmodel file class *.meta file It’s a protocol buffer style file to save the whole model structure and the operation on the model. *.data-xxx file It’s used to save all the value of the model weights. *.index file It’s used to record the correspondence between the model weights and model structure graph. checkpoint file It’s used to record the model name saved on the training process. The record name on the top is the lastest one. check the name and value on the modelby the following way, you can get the variables on the model. It only contains the weights (trainable variables), but no operation. And this command only need *.data and *.index file.12345678910111213# first methodfrom tensorflow.python import pywrap_tensorflowwith tf.Session() as sess: reader = pywrap_tensorflow.NewCheckpointReader('xxx/yyy.ckpt') # need *.index to get key (variable names) for key in reader.get_variable_to_shape_map(): print(key) # it need *.data-xxx to get variable value print(reader.get_tensor(key))# second method# this way also need the *.index and *.data-xxx file.from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_fileprint_tensors_in_checkpoint_file('xxx/yyy.ckpt', None, True, True) view the model graph on the modelIn this way, you can get the model graph such as: variable names, operation names, the inputs operation need and so on. this method only need *.ckpt.meta. Using this method, you can find the placehold name.123456789import tensorflow as tfwith tf.Session() as sess: # load model graph saver = tf.train.import_meta_graph('xxx/yyy.ckpt.meta') graph = tf.get_default_graph() for v in graph.as_graph_def().node: print(v.name) # get the graph node name if not v.input == []: print('\t', v.input) # get the node input item get the tensor from the model and start modelfor using this mothed, you need *.data-xxx file to load model weights. you can get the tensor name from model graph.12345678910with tf.Session() as sess: # load model graph saver = tf.train.import_meta_graph('xxx/yyy.ckpt.meta') # load model weights saver.restore(sess, 'xxx/yyy.ckpt') graph = tf.get_default_graph() input1 = graph.get_tensor_by_name('xxx/w1:0') input2 = graph.get_tensor_by_name('xxx/w2:0') op = graph.get_tensor_by_name('xxx/op_add:0') print(sess.run(op, feed_dict=&#123;input1:1, input2:2&#125;)) add another operation on the model graph sevedusing the operation get from the model graph saved, you can add another operation on it.123456789with tf.Session() as sess: saver = tf.trian.import_meta_graph('xxx/yyy.ckpt.meta') saver.restore(sess, 'xxx/yyy.ckpt') graph = tf.get_default_graph() input1 = graph.get_tensors_by_name('w1:0') input2 = graph.get_tensors_by_name('w2:0') op = graph.get_tensors_by_name('op_add:0') add_op = tf.multiply(op, 2.0) # another operation print(sess.run(add_op)) add another operation on the part of the model graph savedby using the operation not the last one, you can only operate a part of the model saved.12345678910output_n = 3with tf.Session() as sess: saver = tf.train.import_meta_graph('Vgg.meta') graph = tf.get_default_graph() fc7 = graph.get_tensors_by_name('fc7;0') fc7 = tf.stop_gradient(fc7) # stop the gradient spread to the model saved. fc7_shape = fc7.get_shape().as_list() weights = tf.Variable(tf.truncated_normal([fc7_shape[3], output_n], stddev=0.1)) output = tf.matmul(fc7, weights) pred = tf.nn.softmax(output) note: model weigths is saved in the model data *.data-xxx, however placehold is in the model graph *.meta.]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-variables]]></title>
    <url>%2F2019%2F07%2F02%2Ftensorflow-variables%2F</url>
    <content type="text"><![CDATA[variables on the tensorflow, it’s about local, global, model and trainable veriables. local variablesIt’s a variable, but it is defined intf.GraphKeys.LOCAL_VARIABLES, and you can view it by the following command. Just like it’s name, as a local variable, it will not be saved to checkpoint file by default.12local_variables = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES)print(sess.run(local_variables)) The variable defined by default is a global variable, but you can get a local variable by the following method.1local_variable = tf.Variable(6, name='var_l', collections=[tf.GraphKeys.LOCAL_VARIABLES]) note: without any statement, the variables you get in the model and function are also global variables. gloable variablesIt’s the most common variable used in the tensorflow code, and you can get it on the function or model. they are added to the collection,tf.GraphKeys.GLOBAL_VARIABLES, and you can view them by the following method.12global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)print(sess.run(global_variables)) model variablesIt’s defined inside the model, and added to the collection, tf.GraphKeys.MODEL_VARIABLES). you can view them by the following command.12model_variables = tf.get_collection(tf.GraphKeys.MODEL_VARIABLES)print(sess.run(MODEL_variables)) trainable variablesIt’s defined inside the model. In the proces of training, it will be trained. you can find it on the collection, tf.GraphKeys.TRAINABLE_VARIABLES. View them by the following command.12trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)print(sess.run(MODEL_variables)) a example to understand it1234567891011121314151617181920212223import tensorflow as tfdef some_func(): z = tf.Variable(1, name='var_z')a = tf.Variable(1, name='var_a')# get_variable can get a variable existed # or create a variable that does't existb = tf.get_variable('var_b', 2)with tf.name_scope('aaa'): c = tf.Variable(3, name='var_c')with tf.variable_scope('bbb'): d = tf.Variable(3, name='var_d')some_func()some_func()print ([str(i.name) for i in tf.global_variables()])print ([str(i.name) for i in tf.local_variables()])&gt;&gt;&gt;['var_a:0', 'var_b:0', 'aaa/var_c:0', 'bbb/var_d:0', 'var_z:0', 'var_z_1:0'][] The order in the list is the order in which variables are creted. variables in a function are only established when the function is executed, so there are two variables about var_z]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>variables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-numpy]]></title>
    <url>%2F2019%2F07%2F02%2Fpython-numpy%2F</url>
    <content type="text"><![CDATA[numpy using and functions. functionnp.random.shuffle(data)it can shuffle a data structure such as numpy array or list. and this function don’t return any value, it do this operation on the data itself.1234data_list = [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6]]data_array = np.arange(16).reshape([4, 4])np.random.shuffle(data_list) np.random.shuffle(data_array) np.squeeze(data, axis=None)squeeze the data array.1234a = np.arange(4).reshape([1,2,2,1])a.shape =&gt; [1,2,2,1]b = np.squeeze(a)b.shape =&gt; [2,2] using]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm-cmd]]></title>
    <url>%2F2019%2F07%2F02%2Fnpm-cmd%2F</url>
    <content type="text"><![CDATA[the using of the npm common commandinstallinstall on the local projectthis way will install package to ./node_modules, and it is only alive on the local project.1npm install modulename install on the global projectthis way will install package on ./usr/local or node.js installing folder, and you can use them on the system terminal.1npm install modulename -g uninstall1npm uninstall modulename list moldule123npm list // view the local installing modulenpm list -g // view the global installing modulenpm list modulename // view the module installing message change the domestic registry12npm config get registry # view the default registrynpm config set registry http://registry.npm.taobao.org # change the default registry to the Ali registry show the installing progress1npm install -d modulename]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter-setting]]></title>
    <url>%2F2019%2F07%2F02%2Fjupyter-setting%2F</url>
    <content type="text"><![CDATA[jupyterLab, automatic completion, code tips jupyterLab is the next generation product of the jupyter install jupyterLabinstall12pip install jupyterLabpip install ipython generate password123ipythonfrom notebook.auth import passwdpasswd() copy the password generated generate config file1jupyter lab --generate-config adjust as the following code12345c.NotebookApp.ip='*'c.NotebookApp.allow_root = Truec.NotebookApp.open_browser = Falsec.NotebookApp.password = 'passwore generated'c.NotebookApp.port =8888 command1234jupyter labextension install @jupyterlab/toc # install pluginjupyter labextension list # view the installed pluginjupyter-lab --ip=xx.xx.xx.xx # start jupyterLabc.NotebookApp.notebook_dir = 'F:\python\jupyter' # start dir Now, you can find it on your browser enable the plugin ico12setting -&gt; advanced settings editorfalse -&gt; true]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[batch-normalization]]></title>
    <url>%2F2019%2F07%2F02%2Fbatch-normalization%2F</url>
    <content type="text"><![CDATA[Theory and application of batch normalization theory提出At recent years, Batch Normalization is considered an important achievement and has proven to be effective in many applications. 虽然有些处理还解释不清楚理论原因，但是实践证明好用才是真的好。而且深度学习从Hinton对深度网络做与训练开始就是一个经验领先于理论分析的偏经验的学问。机器学习领域有个很重要的假设IID独立同分布假设，假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试数据上获得效果的一个基本保障。实际上并不是这样，Batch Normalization就是在深度网络训练过程中使得每一层网络的输入保持相同的分布。 internal covariate shift problemcovariate shift problem如果数据集中的输入数据的分布老是变化，不符合IID的假设，网络模型很难得到稳定。 internal covariate shift problem在训练的过程中，因为各层参数不定在变化，所以每个隐含层都会面临convriate shift problem。batch normalization的基本思想就是：能不能让每个隐含层节点的激活输入分布固定下来，以避免internal convariate shift problem。 前人的成果BN的想法并不是凭空出来的，之前的研究就发现在对输入图像进行白化操作的话，神经网络就会更快的收敛，所以BN的作者提出，对网络的输入数据进行白化操作能够加快收敛，那么对网络的每一个隐含层都进行白化处理会不会有更好的效果呢。 Batch Norm的本质思想深度网络训练收敛越来越慢的本质原因是梯度消失，而BN通过一定的规范化手段，把每层神经网络任意神经元的输入值的分布强行拉回到均值为0方差为1的标准正态分布，使激活函数输入值落在对输入数据比较敏感的区域。优点： 可以使用较大的学习率，能够加快模型的收敛速度。 能够起到正则化的效果，在一些情况下可以不适用Dropout，因为BN提高了模型的泛化能力。 how to do it对mini batch SGD来说数据从第t-1层流入第t层 x_{t}=Wx_{t-1}+B对t-1层来的数据进行变换 \mu_{B}=\frac{1}{m_{B}}\sum_{i=1}^{m_{B}}x^{(i)} \sigma_{B}^2=\frac{1}{m_{B}}\sum_{i=1}^{m_{B}}(x^{(i)}-\mu_{B})^2\hat{x}^{(k)}=\frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(x)}]}}为了保证网络的表达能力对变换后的数据流进行线性变换，是对数据分布的重构其中$\gamma$和$\beta$是无门需要学习的参数 y^{(k)}=\gamma^{(k)}\hat{x}^{(k)}+\beta^{(k)}推理过程在mini-batch中先计算出每一个batch中的均值和方差，然后根据一下方法计算出全局的均值和方差 E[x]\gets{E_{B}[\mu_{B}]} Var[x]\gets\frac{m}{m-1}E_{B}[\sigma_{B}^{2}] y=\frac{\gamma}{\sqrt{Var[x]+\varepsilon}}\cdot{x}+(\beta-\frac{\gamma\cdot{E[x]}}{\sqrt{Var[x]+\varepsilon}})applicationbatch normalization在实现的时候会记录下训练数据中的均值和方差，记为: moving_mean, moving_variance，在训练的时候用moving_mean, moving_ariance进行计算，这也就是参数training的作用，在实现时一般使用一个decay系数来逐步更显moving_mean, moving_variance。1moving_mean = moving_mean * decay + new_batch_mean*(1-decay) 在batch normalization中更新mean和variance的操作并不会自动执行，它们会保存在tf.GraphKeys.UPDATE_OPS集合中，这些操作需要在模型进行计算之前执行。如下所示123update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)with tf.control_dependencies(updata_ops): train_op = optimizer.minize(loss)]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>slim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-cmd]]></title>
    <url>%2F2019%2F07%2F02%2Fgit-cmd%2F</url>
    <content type="text"><![CDATA[git command test the ssh key1ssh -T git@github If it’s working, you will get the following response1Hi xxx! You've successfully authenticated, but GitHub does not provide shell access.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matplotlib]]></title>
    <url>%2F2019%2F07%2F02%2Fmatplotlib%2F</url>
    <content type="text"><![CDATA[matplotlib using and Error usingsave picture123y = np.sin(x)plt.plot(y)plt.savefig(filename, dpi=xxx) dpi is the optional parameter for the picture, use it to choose the quality of the image. use multiple drawing boxesdon’t use plt.show on the end of the picture, you will get two picture on once.12345plt.figure(1)plt.plot(x)plt.figure(2)plt.plot(y)plt.show() close drawing axis1plt.axis('off') dynamic displayyou can dynamic display picture and analyse the data change.12345for i in range(..): plt.clf() plt.plot(data[i]) plt.pause(delay_time)plt.show() if you want to see the history data, do not use the clear command.1234for i in range(..): plt.plot(data[i]) plt.pause(delay_time)plt.show() ErrorRuntimeError: Invalid DISPLAY variablereason:the default backend of the matplotlib is TkAgg, but the FltAgg, GTK, GTKCairo, TkAgg need the GUI. So it will meet error when using sshsolution:you can use this backend, Agg, Cairo, PS, PDF and SVG, they don’t need GUI.12import matplotlib.pyplot as pltplt.switch_backend('agg)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http-raspberry]]></title>
    <url>%2F2019%2F07%2F02%2Fhttp-raspberry%2F</url>
    <content type="text"><![CDATA[build a http server on raspberry centos7. install httpd1yum install httpd config httpd configure file1234vi /etc/httpd/conf/httpd.conf&gt;&gt; Listen 80 # http listen portDocumentRoot "/var/www/html" # the html file directory view the port using12firewall-cmd --query-port=80/tcpfirewall-cmd --query-port=80/udp if you get ‘no’, this neams the port is free. open the 80 port fot the http server12firewall-cmd --permanent --zone=public --add-port=80/tcpfirewall-cmd --permanent --zone=public --add-port=80/udp restart firewall1firewall-cmd --reload start httpd service1service httpd start set service boot on system boot1systemctl enable httpd]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>raspberry</tag>
        <tag>centos7</tag>
        <tag>http server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[raspberry-system-install]]></title>
    <url>%2F2019%2F07%2F02%2Fraspberry-system-install%2F</url>
    <content type="text"><![CDATA[install raspberry centos7 install centos7download systemchoose the system you need from Centos system website. and choose the raspberryPi GNOME system. formate SD carduse SD card formatter to fromate your SD card. install systemuse Win32DiskImager to install centos system to your SD card. log in systemdefault user and password12user: rootpassword: centos expend SD free spacewhen you log in system, you will find little exsiting space of the system. you can expend the SD card free space for the system by the following command.1rootfs-expand]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>raspberry</tag>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activate-function]]></title>
    <url>%2F2019%2F07%2F02%2Factivate-function%2F</url>
    <content type="text"><![CDATA[activate function ELU f(x)=\Big\{ { {x \atop \alpha(e^2-1)} \quad {x>0 \atop x \le 0}}LReLU f(x_i)=\Big\{ { {x_i \atop a_i x_i} \quad { x_i >0 \atop x_i \le 0}}where $a_i$ is a constant number. You can set it by the following command1tf.nn.leky_relu(features, aplpha=a, name=None) PReLU f(x)=\Big\{ { {x_i \atop a_i x_i} \quad {x_i > 0 \atop x_i \le 0}}where $a_i$ can be adjust during the training process. CReLU CReLU(X) = [ReLU(x),ReLU(-x)]you can use the following command to use this function.1tf.nn.crelu(features, name=None) ELU f(x) = \Big\{ { { x \atop \alpha(e^2-1)} \quad {x>0 \atop x\le 0}}using the following command, you can use this function.1tf.nelu(features, name=None) SELU f(x)=\lambda\Big\{ { { x \atop \alpha(e^x-1)} \quad {x>0 \atop x\le 0}}the function in the tensorflow is like the following one1tf.nn.selu(features, name=None)]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sftp-cmd]]></title>
    <url>%2F2019%2F06%2F28%2Fsftp-cmd%2F</url>
    <content type="text"><![CDATA[using of the sftp common commandlog in1sftp user@ip log out12exit # function 1quit # function 2 put12put file # upload a fileput -r directory # recurisively upload a folder get12get file # download a fileget -r directory # recurisively download a folder show current folder path12pwd # show the remote folder pathlpwd # show the local folder paht show files and directory in the cuttent directory12ls # show the remote files and folder on the remote directorylls # show the local files and folder delete file or folder12rm file # delete the filermdir folder # delete the folder, the folder must be empth. environmental configurationadd a common user for the sftp serverthe common user can be used for the hexo deploy create sftp group 1groupadd sftp create a user for sftp group 1useradd -g sftp xxx specity a directory for the user 1usermod -d xxx/sftp/sftp1 sftp1 restart sshd service 1service sshd restart without password log in sftpadd the sftp user confirm the openssh version, it must greter 4.8p. 1ssh -V create sftp group 1groupadd sftp create a sftp user named sftp1 12useradd -g sftp -s /sbin/nologin sftp1 # reject user login with polite languageuseradd -g sftp -s /bin/false sftp1 # reject user login without any tip specify a directory for the sftp user 12mkdir -p xxx/sftp/sftp1 # -p means that if sftp folder is not existed, the command will creat one.usermod -d xxx/sftp/sftp1 sftp1 # specify a home directory for sftp1 user config the sshd_config file 1234567891011vi /etc/ssh/sshd_config&gt;&gt;comment the following oneSubsystem sftp /usr/libexec/openssh/sftp-server&gt;&gt; add the following linesSubsystem sftp internal-sftpMatch Group sftp # user groupChrootDirectory xxx/sftp/sftp1 # user home directoryForceCommand internal-sftpAllowTcpForwarding noX11Forwarding no set directory permissions 12chown root:sftp xxx/sftp/sftp1 # set the directory belong to root user and sftp group.chmod 755 xxx/sftp/sftp1 # set the permissions disable linux security enhanced module 12345vi /etc/selinux/config&gt;&gt; configSELINUX=disable # disable the module&gt;&gt; exitsetenforce 0 # close selinux firewall restart sftp service 1service sshd restart confirm the sftp service 1sftp sftp1@xx.xx.xx.xx log in the sftp server using user and password. if it work, the configure is right. config the key create key on the client computer 1ssh-keygen you can get two file on the ~/.ssh directory.12id_rsa # private keyid_rsa.pub # public key move the public key to the server and rename it authorized_keys 12client home path/.ssh/id_rsa.pub -&gt; server home path/.ssh/id_rsa.pubcat id_rsa.pub &gt;&gt; authorized_keys set the pressions for the directory .ssh 1chown sftp1:sftp xxx/sftp/sftp1/.ssh confirm the user login 1sftp sftp1@xxx.xxx.xxx.xxx]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[raspberry-centos7-ip]]></title>
    <url>%2F2019%2F06%2F28%2Fraspberry-centos7-ip%2F</url>
    <content type="text"><![CDATA[setting for static ip on the raspberry centos. set the ip configure fileIf you can’t find the configure file ifcfg-eth0 on the raspberry centos system, you could create it for the system by the following command.1vi /etc/sysconfig/network-scripts/ifcfg-eth0 and add or adjust the content as the following.1234567891011DEVICE=eth0 # device nameBOOTPROTO=static # using static ipBROADCAST=192.168.0.255HWADDR=b8:27:eb:8a:cb:58 # hwadd (also called ether)IPADDR=192.168.0.186 # static ipIPV6INIT=noIPV6_AUTOCONF=noNETMASK=255.255.255.0 # netmaskGATEWAY=192.168.0.1 # default gateway# DNS1=114.114.114.114 # DNSONBOOT=yes # using this config on boot restart the server1service network restart]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>raspberry</tag>
        <tag>centos7</tag>
        <tag>static ip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10-ftp]]></title>
    <url>%2F2019%2F06%2F21%2Fwin10-ftp%2F</url>
    <content type="text"><![CDATA[configure the ftp evrironment on the win10 cumpyter. add ftp servicecontrol panel &gt; program &gt; start and close the windows projectInternet Information Services &gt; choose the following items FTP services FTP extensibility IIS Management Console create ftp serverstart IIS Manager &gt; add ftp site name message ftp-site-name name physical-paht file-paht ip-address ip SSL without-ssl authentication anonymity-or-basic authorization any-user authorization read-or-write configure firewallIf you want to use the server on local area network, you should let the special server pass through the firewall.Control panel &gt; systems and security &gt; windows defender &gt; allow apps or function to pass through windows defenderallow ftp server pass through private and public networksallow another apps &gt; C:\Windows\System32\svchost.exeNow, you can transfer files over the network.]]></content>
      <categories>
        <category>win10</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>win10</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycharm-remote]]></title>
    <url>%2F2019%2F06%2F19%2Fpycharm-remote%2F</url>
    <content type="text"><![CDATA[build pycharm remote debugging function set python remote interpreterHow to use remote interpreter.File &gt; Settings &gt; Project: xxx &gt; Project Interpreter &gt; Add Remote &gt; SSH CredentialsSSH Credentials options content Host ip Port port User-name user_name Password xxx Python-interpreter-path remote-python-interpreter-path Path mappingsLocal Path &lt;—&gt; Remote Path set deployment for the synchronization of local and remote filesTools &gt; Deployment &gt; Configuration &gt; +Connection options content name deployment_name Type SFTP SFTP-host ip Port port Root-Path remote-root-path User-name user_name Password xxx Advanced-options UTF-8 Mappings options content Local-path local_path Deployment-path-on-server remote-deployment-paht enable the deployment path on server, you can upload and download files between local and remote filesTools &gt; Deployment &gt; Browse Remote Host set python version running on the terminalFile &gt; Setting &gt; Tools SSH Terminal &gt; Deployment serverYou can choose the python interpreter you need from the tips. And choose UTF-8 as the default encoding.Now, you can find the interpreter ont Tools &gt; Start SSH session. set configurationsconfigure python remote debug you needRun &gt; Edit Configurations &gt; + &gt; Python Remote Debug options content Name name Local-host-name ip Port port-greater-than-1003 Path-mappings Local-path&lt;—&gt;Remote-path the Path mappings like the set python remote interpreterNow, add the environment variables CUDA need.Run &gt; Edit Configurations &gt; Defaults &gt; python &gt; Environment variables environment-variables cotent CUDA_DEVICE_ORDER PCI_BUS_ID LD_LIBRARY_PATH ”$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64” CUDA_HOME /usr/local/cuda CUDA_VISIBLE_DEVICES 0,1 TF_CPP_MIN_LOG_LEVEL 1 Maybe, there are some error about cuda, you can use the following command to view the equipment remote python interpreter can use. If you don’t find the GPU on the printed message, you could adjust CUDA_VISIBLE_DEVICES content to find the right equitment.12from tensorflow.python.client import device_libprint(debice_lib.list_local_devices()) Ok, enjoy your new toy!]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pycharm</tag>
        <tag>remote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua-cmd]]></title>
    <url>%2F2019%2F06%2F08%2Flua-cmd%2F</url>
    <content type="text"><![CDATA[install Lua installation Download the binary file lua-5.3.5_Win64_bin.zip form the offical website Upzip *.zip to get the following file and adjust the file name to the right one 1234lua53.exe --&gt; lua.exeluac53.exe --&gt; luac.exewlua53.exe --&gt; wlua.exelua53.dll Add the file path to the environment path.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode-Plugin]]></title>
    <url>%2F2019%2F06%2F05%2FVSCode-Plugin%2F</url>
    <content type="text"><![CDATA[describe the VSCode Plugin, install, settingnote: It’s working. fundamental concepttask: running a script once.task.json: setting file about task.working space: the working folder.setting.json: setting file of the working space. you can find a button on the bottom right corner, and click it you will find the setting button.launch.json: setting file of debug environment. Markdown pluginMarkdown All in OneSome shrotcuts for markdown editing Markdown Preview Github StylingChange VSCode’s built-in markdown preview to match Github’s style Markdown ShrotcutsSome shortcuts for markdown editing python pluginPythonpython official pluginsetting.json12"python.pythonPath": "E:/Anaconda3/envs/tf-gpu/python","python.linting.pylintPath": "E:/Anaconda3/envs/tf-gpu/Scripts", the first one is thepython.exe‘s path.the second one is thepylint.exe‘s path. It’s a code analysis tool, and you can install it by the following command:1pip install pylint tasks.jsonrun python file shortcut:Ctrl+Shift+Bset the default template to create tasks.json12command # the script to runargs # the paraments set for running. using this "$&#123;file&#125;" lunch.jsonclick the debug icon on the left bar, and find the setting button on the top bar.now, it’s time for you to debug you code. Visual Studio IntelliCodeCode completion automaticallysetting.jsonadd the following command to the setting file.123456"python.autoComplete.extraPaths": [ "E:/Anaconda3/envs/tf-gpu", "E:/Anaconda3/envs/tf-gpu/Lib", "E:/Anaconda3/envs/tf-gpu/Lib/site-packages", "E:/Anaconda3/envs/tf-gpu/DLLs"]]]></content>
      <categories>
        <category>VSCode</category>
      </categories>
      <tags>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[anaconda-cmd]]></title>
    <url>%2F2019%2F06%2F05%2Fanaconda-cmd%2F</url>
    <content type="text"><![CDATA[inistall anaconda on the win10, set environment variables, and some operation command. inistall download the latest installation file from anaconda official website select the default installing option set the environment variablesadd the system environment path $PATHwith the following anaconda installing path:123Anaconda3Anaconda3/ScriptsAnasonda3/Library/bin operation commandcreat new working environment1conda create -n environment_name [python=x.x] you can select the python version, and the default version is the one in conda activate the working environment1activate environment_name deactivate the wroking environment1deactivate environment_name remove the wroking environment1conda remove -n environmtne_name --all view currently available working environment12conda info --envconda info -e change the pip source to speed up download make flolder named pip on the C:\Users\xx\ add the setting file pip.ini to this flolder C:\Users\xx\pip\pip.ini 12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple uninstall Anacondafind the Uninstall-Anaconda.exe on the installing path, and running it. clone the existing environment1conda create -n new_e --clone old_e]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>anaconda</tag>
        <tag>inistall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10-cuda-cudnn-tensorflow]]></title>
    <url>%2F2019%2F06%2F04%2Fwin10-cuda-cudnn-tensorflow%2F</url>
    <content type="text"><![CDATA[install cuda10.1,cudnn7.6,tensorflow1.13.1 install CUDA download the cuda filecuda_10.1.168_425.25_win10.exe from the CUDA official website select the default installing option set the environment variables as following 123456789101112# new system environment variablesCUDA_SDK_PATH = C:\ProgramData\NVIDIA Corporation\CUDA Samples\v8.0CUDA_LIB_PATH = %CUDA_PATH%\lib\x64CUDA_BIN_PATH = %CUDA_PATH%\binCUDA_SDK_BIN_PATH = %CUDA_SDK_PATH%\bin\win64CUDA_SDK_LIB_PATH = %CUDA_SDK_PATH%\common\lib\x64# add to system variable PATH%CUDA_LIB_PATH%;%CUDA_BIN_PATH%;%CUDA_SDK_LIB_PATH%;%CUDA_SDK_BIN_PATH%;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\lib\x64；C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\bin；C:\ProgramData\NVIDIA Corporation\CUDA Samples\v8.0\common\lib\x64；C:\ProgramData\NVIDIA Corporation\CUDA Samples\v8.0\bin\win64； check whether the CUDA works properly by the following command 1234nvcc -Vcd NVIDIA GPU Computing Toolkit\CUDA\v10.1\extras\demo_suitedeviceQuery.exebandwidthTest.exe install cudnn downloading the cudnn filecudnn-10.1-windows10-x64-v7.6.0.64.zipfrom the CUDA official website copy the cudnn files to the corresponding CUDA folder. install Anaconda downloading the Anaconda installation file for the Anacoada official website set the environment variables create python3.7 working environment 1conda create -n environment_name python=3.7 download the tensorflow-gpu installing file tensorflow_gpu-1.13.1-cp37-cp37m-win_amd64.whl install this file under the working environment 1pip install xxx.whl check whether it works properly 1234import tensorflow as tfsess = tf.Session()a = tf.constant([1, 2, 3])print(sess.run(a)) ok, enjoy it.]]></content>
      <categories>
        <category>win10</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>win10</tag>
        <tag>cuda</tag>
        <tag>cudnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-cmd]]></title>
    <url>%2F2019%2F06%2F02%2Flinux-cmd%2F</url>
    <content type="text"><![CDATA[linux 中的常用命令: 压缩， 文件压缩压缩文件类型 tools file type zip,unzip *.zip tar .tar.gz, .tar zip 压缩 1zip -r myfile.zip ./* 将当前目录下的所有文件压缩到myfile.zip中，其中-r表示递归操作note: 如果myfile.zip存在，则向其中添加文件 解压缩 1unzip -o -d /usr/local/ myfile.zip 将myfile.zip中的内容解压到/sur/local/文件夹下-o不提示的情况下覆盖文件-d指明解压缩到的文件夹 多压缩文件的操作 1zip -d myfile.zip a.txt 删除压缩文件中的a.txt文件1zip -m myfile.zip b.txt 向myfile.zip中移入文件b.txt，复制+删除 多文件操作 1zip -r file.zip f1 f2 /usr/local 将多个文件和文件夹压缩到file.zip中 tar 参数 这5个命令要用且只能用到其中的一个 name operation -c 建立压缩档案 -x 解压 -t 查看内容 -r 向压缩归档文件末尾追加文件 -u 更新原压缩包中的文件 这5个参数可以视情况使用 name operation -z： 有gzip属性的 -j： 有bz2属性的 -Z： 有compress属性的 -v： 显示所有过程 -O： 将文件解开到标准输出 查找find1find path -option [-print] [-exec -ok command] &#123;&#125; \ option prediction -amin n 在过去几分钟被读取过 -anewer file 比文件file更晚被读取过 -atime n 在过去几天内被读取过 -cmin n 在过去几分钟被读取过 -cnewer file 比文件file更新被读取过 -ctime n 在过去几天内被读取过 -name name 文件名称为name的文件 -iname name 文件名称为name的文件，区分大小写 -type c 文件类型是c的文件 文件的名字支持模糊查找*.c -type c prediction d 目录 c 字节型装置文件 b 区块装置文件 f 一般文件 l 符号链接 可以使用( )将运算式分离12345(exp1 -and exp2)(! exp1)(-not exp1)(exp1 -or exp2)(exp1, exp2) 例子123456find . -name "*.c"find . -type ffind . -ctime -20 # 列出目录下最近20天内更新过的文件find . -type f -mtime +7 -ok rm &#123;&#125;\ # 找到目录下在7天前改变的文件，并在删除前询问它们find . -type f -prem 644 -exec ls -l &#123;&#125; \ # 找到具有读写权限，冰鞋文件所属用户和其他用户具有读写权限的文件find . -name '*.c' -exec grep -l 'open' &#123;&#125; \ # 找到当前目录下c文件中包含‘open'字符串的文件 grep用来全面搜索正则表达式，并把行打印出来1grep [-option] pattern file option message -i ignore-case -w match-word -l match-file-content -m match-file-number wc1wc -option [file] 统计指定文件中的字节数、字数、行数。如果没有指定文件名则从标准输入读取。 option message -c byte-number -l line-number -m chart-number sed1sed [-nefri] 'command' input_text option message -n 使用安静模式 -f+f_name 执行f_name内的sed命令 -i 直接修改读取的档案内容 command message a add c replace some line d delete i insert p print g replace some charts with another s replace with regular expressions example123456789101112sed '1d' f # 删除f中的第一行sed '$d' f # 删除f中的最后一行sed '1,2d' f # 删除f中的第1，2行sed -n '1p' f # 显示f中的第一行sed -n '/ruby/p' f # 查询包括ruby关键字的行sed -n '/\$/p' f # 查询包括$关键字的行sed '1a drink tea' f # 在第一行后增加字符串drink teased '1c songshu' f # 把第一行代替为songshused '1,3c songshu' f # 把第一行到第三行替换为songshused 's/string/sognshu/g' # 在一行中将string替换为songshused -i '/test/s/test/songshu/' f # 将f中的test替换为songshused -i 's/ *//' f # 删除f中行首的空格 uniq1uniq -option [file_name] option message -c count-the-same-line -d only-print-the-repeated-line -f skip-some-words -i ignore-case -s skip-some-charts -u unique -w check-the-first-n-charts sort1sort -option [-o out_file] [-t split chart] [+start-end] [file_name] otion message -b ignore-space-chart-at-start -n positive-order -r reverse-order 查看CPU信息查看物理cpu个数1cat /proc/cpuinfo | grep "physical id" | sort | uniq | wc -l 查看每个物理cpu中核的个数1cat /proc/cpuinfo | grep "cpu cores" | uniq 查看逻辑cpu的个数1cat /proc/cpuinfo | grep "processor" | wc -l]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo Markedown 语法]]></title>
    <url>%2F2019%2F05%2F12%2Fhexo-Markedown-%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Markdown 是一种标记语法，使用简单的文本格式来表达复杂的标记语言。基本的语法介绍。 标题12# 一级标题## 二级标题 快捷键： (提高文字等级，降低文字等级)Ctrl+Shift+[ / ] 常用语法 表达式 描述 快捷键 **txt** 粗体 Ctrl+B _txt_ 斜体 Ctil+I _**txt**_ 加粗斜体 Ctrl+B+I ~~txt~~ 删除线 - 引用块1&gt; txt... 代码块1234`行内代码`` ``多行代码` `` 快捷键：行内 | 多行Ctrl+M+I | Ctrl+M+C 公式块123$$数学公式$$ 快捷键：(Ctrl+M冲突，改为Ctrl+Alt+M)Ctrl+Alt+M更多公式语法 分割线123---+++*** 列表123456有序列表，显示数字1. ...无序列表，显示点* ...+ ...- ... 快捷键：有序列表 | 无序列表Ctrl+M+1 | Ctrl+M+B 表格1234| head1 | head2 || ----- | ----- || txt1 | txt2 || txt3 | txt4 | 快捷键：Ctrl+Alt+T在表头下添加：可以进行左对齐，右对齐，中间对齐 超链接1[连接文字](链接地址) 快捷键：Ctrl+L + url 图片1![图片文字](图片地址 “图片描述”) 使用 hexo-asset-image 插件可以在创建文章时生成一个同名的文件夹用来存储图片快捷键：Ctrl+Shift+L + url 模板设置在/scaffolds/post.md中可以修改新建文章的模板12345---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:---]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 命令]]></title>
    <url>%2F2019%2F05%2F10%2Fhexo-cmd%2F</url>
    <content type="text"><![CDATA[hexo 使用的常用命令，初始化，建立新章节，添加新的属性，生成静态文件，发布以及配置数学公式的支持 inistallinstall node.js官网下载node.js安装包，会默认安装npm install hexo1npm install -g hexo 使用git cmd或者windows cmd安装 setting the support of Latex change the Markdown rendering engine 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save set the config fileadjust the config file node_modules\kramed\lib\rules\inline.js 123456&gt;&gt; 11 line//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,&gt;&gt; 20 line//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, open the MathJax on the themeopthe the config file _config.yml under the theme, enable the math equations render supprot 12345678910math: enable: true # Default(true) will load mathjax/katex script on demand # That is it only render those page who has 'mathjax: true' in Front Matter. # If you set it to false, it will load mathjax/katex srcipt EVERY PAGE. per_page: true engine: mathjax #engine: katex open the MathJax on the blog front matterusing the following command on the blog front matter to render the math equations. 123456---title: index.htmldate: 2018-07-05 12:01:30tags:mathjax: true--- add the search function install the module 1npm install hexo-generator-searchdb --save config global config fileadd the following content to the global config file. 12345search: path: search.xml field: post format: html limit: 10000 config theme config fileenable the lodal_search 123456789# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 add feed inistall hexo-generator-feed 1npm install hexo-generator-feed --save config global config file 1234567891011_config.yml# Extensions## Plugins: http://hexo.io/plugins/#RSS订阅plugin:- hexo-generator-feed#Feed Atomfeed: type: atom path: atom.xml limit: 20 config theme config file 1rss: /atom.xml add flow and sequence graph install hexo-filter-flowchart 1npm install --save hexo-filter-flowchart config global file for flow graph 1234flowchart: # raphael: # optional, the source url of raphael.js # flowchart: # optional, the source url of flowchart.js options: # options used for `drawSVG using flow graph 123456789101112131415st=&gt;start: Start|past:&gt;http://www.google.com[blank]e=&gt;end: End:&gt;http://www.google.comop1=&gt;operation: My Operation|pastop2=&gt;operation: Stuff|currentsub1=&gt;subroutine: My Subroutine|invalidcond=&gt;condition: Yesor No?|approved:&gt;http://www.google.comc2=&gt;condition: Good idea|rejectedio=&gt;inputoutput: catch something...|requesttruest-&gt;op1(right)-&gt;condcond(yes, right)-&gt;c2cond(no)-&gt;sub1(left)-&gt;op1c2(yes)-&gt;io-&gt;ec2(no)-&gt;op2-&gt;e install hexo-filter-sequence 1npm install --save hexo-filter-sequence config global configure file for sequence graph 12345678910_config.ymlsequence: raphael: https://cdn.bootcss.com/raphael/2.2.8/raphael.min.js webfont: https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js snap: https://cdn.bootcss.com/snap.svg/0.5.1/snap.svg-min.js underscore: https://cdn.bootcss.com/underscore.js/1.9.1/underscore-min.js sequence: https://cdn.bootcss.com/js-sequence-diagrams/1.0.6/sequence-diagram-min.js # css: # optional, the url for css, such as hand drawn theme options: theme: simple config source code it is near line 28.12345678render.js// resourcesdata.content += '&lt;script src="' + config.webfont + '"&gt;&lt;/script&gt;';// sequence-diagram 1.x 版本依赖 raphael, 2.x版本依赖 snapdata.content += '&lt;script src="' + config.raphael + '"&gt;&lt;/script&gt;';data.content += '&lt;script src="' + config.snap + '"&gt;&lt;/script&gt;';data.content += '&lt;script src="' + config.underscore + '"&gt;&lt;/script&gt;';data.content += '&lt;script src="' + config.sequence + '"&gt;&lt;/script&gt;'; using sequence graph using the flag sequence.123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! add meraid graphthis is a beautiful tool to create node graph. if you using hexo next theme, perhaps installing is easy as following first two steps. install mermaid plugin 1npm install hexo-filter-mermaid-diagrams open the local config mermaid option. 1234567# Mermaid tagmermaid: enable: true # Available themes: default | dark | forest | neutral theme: forest cdn: //cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js #cdn: //cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js if this is not work, do the following steps. config global configure file. 123456# mermaid chartmermaid: ## mermaid url https://github.com/knsv/mermaid enable: true # default true version: "7.1.2" # default v7.1.2 options: # find more api options from https://github.com/knsv/mermaid/blob/master/src/mermaidAPI.js #startOnload: true // default true edit footer.swig file this file is on the folder xxx/next/layout/_partials12345678&#123;% if theme.mermaid.enable %&#125; &lt;script src='https://unpkg.com/mermaid@&#123;&#123; theme.mermaid.version &#125;&#125;/dist/mermaid.min.js'&gt;&lt;/script&gt; &lt;script&gt; if (window.mermaid) &#123; mermaid.initialize(&#123;&#123; JSON.stringify(theme.mermaid.options) &#125;&#125;); &#125; &lt;/script&gt;&#123;% endif %&#125; Now, if search merain on the html file, you will find the the following code block parsed by plugin, this means the plugin is work. but if you do not view mermaid graph on the brower, check whether there is a javerscript named mermaid.min.js on the heml file. a example graph TD; A-->B; A-->C; B-->D; C-->D; deployusing githubinstall git官网下载git安装包，一路next install hexo-deployer-git1npm install hexo-deployer-git --save setting ssh key for git generate ssh key 1ssh-keygen -t rsa -C "email@xxx.com" if reach any error, delete the older ssh key file in the .ssh/ submit public key copy the public key in .ssh/id-rsa.pubto the github web asssociating blog and githubedit the file_config.ymlin the porject directory1234deploy: type: git repository: git@github.com:xxx/xxxe.github.io.git branch: master using sftpinstall hexo-deployer-sftp1npm install hexo-deployer-sftp --save config the configure filechange the global configure file _config.yml123456deploy: type: sftp host: 192.168.0.186 user: httpserver pass: songshu*ftp remotePath: / operationinit1$ hexo init [folder] 新建一个网站，使用folder指定文件夹，默认为当前文件夹。 new1$ hexo new [layout] &lt;title&gt; 新建一篇文章，如果没有设置layout则默认使用_config.yml中的default_layout参数。如果标题中使用空格，需要使用引号括起来 draftIt will create a file under the folder source/_drafts.1hexo new draft &lt;title&gt; 新建一篇草稿，草稿并不会被更新到服务器端的个人博客中，会在本地文件夹source\_drafts中新建一个md文件 publish1hexo publish [layout] &lt;filename&gt; 公布草稿为博客 page为博客添加新的属性（tag,…）12$ hexo new page tags$ hexo new page categories 会在相应在source文件夹下生成相应的markdown文件，分别在每个文件头处添加：12$ type: "tags"$ type: "categories" 添加完属性后需要在文件头出添加相应的标记，或者在布局模板上添加设置，模板的设置如下所示。123fild: xx\scaffoldstags:categories: generate1$ hexo g 生成静态文件 选项 描述 -d 文件生成后部署到网站上 -w 监视文件变动 server1$ hexo server 启动服务器，本地查看 选项 描述 -P 重设端口 -s 只是用静态文件 -l 启动日记记录，使用覆盖记录格式 —drafts 查看草稿 deploy1$ hexo d 部署网站到远端服务器 参数 描述 -g 部署之前预生成静态文件 clean1$ hexo clean 清除缓存文件和已经生成的静态文件。在某些情况下，尤其是更换主题后，如果发现站点的更换无论如何也不生效，可能需要运行该命令。 list1$ hexo list &lt;type&gt; 列出网站资料 调试模式1$ hexo --debug 在终端显示调试信息并记录到debug.log文件中。 生成并发布1$ hexo d -g set skip item for the hexo systemyou can find the skip_render on the _config.yml12345skip_render: xx.d # skip one fileskip_render: *.d # skip a set of file named *.dskip_render: file/* # skip a folderskip_render: file/** # skip a folder and the subfolderskip_render: [*.d, file/*, file/**] # skip different type Error Error: Spawn failed check the ssh key check the sshst=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request true st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);Alice->Bob: Hello Bob, how are you? Note right of Bob: Bob thinks Bob-->Alice: I am good thanks!{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("sequence-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value)); var diagram = Diagram.parse(code); diagram.drawSVG("sequence-0", options);]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
